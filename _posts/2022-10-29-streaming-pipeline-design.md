---
layout: post
title:  "스트리밍 파이프라인 설계"
date:   2020-10-29 07:02:00 +0900
categories: psyoblade created

---

## 스트리밍 파이프라인 설계

>  데이터 메시 아키텍처를 그리면서 우리에게 필요한 기반 기술 그리고 어떤 방향으로 아키텍처가 그려져야만 바람직한 지를 고민하게 되었다. 기존에 배치 파이프라인의 경우 충분히 안정적이고 잘 운영되고 있어 추가적인 변화는 필요 없어 보인다. 다만, 스트리밍의 경우는 하나의 서비스에 적용되어 왔고, 이 또한 람다 아키텍처 기반의 기술에 최적화 되어 있어 아직은 완성도가 높지 않다. 그리고 스트리밍 파이프라인이 명확하게 어떤 특징이 있고 어떤 문제점들이 많은 지에 대해 고민해볼 기회가 적었다고 할까 ...
>  아무튼 현재 우리에게 필요한 것은 배치와 더불어 스트리밍 파이프라인에 대한 경험, 운영 능력 그리고 제품을 설계할 수 있는 능력을 가지게 하는 것이다. 또한 데이터 아키텍처 수준에서 다양한 유형 (정적, 스트리밍 등)의 데이터 소스를 제공할 수 있는 인프라를 경험한다는 차원에서 아주 유용하다고 생각한다. 유용하다기 보다... 완전체가 되는 느낌이다. ;-) 

## 일단 나열해 보기

* 당장 수행해야 할 과제는 카프카와 같은 스트리밍 소스가 존재할 때에 이를 어떻게 활용하는 방법(누구나 쉽게 사용할 수 있는 접근성)을 제공하는 것
* 데이터 제품으로써의 품질과 인프라 수준에서 제공해야 하는 특징 및 기능을 어떻게 녹여낼 수 있는가(배치, 스트리밍 공히 필요함)
  * 커넥트를 통해서 정적 데이터 소스를 생성하고 서비스하는 관점의 개발이 필요하고
  * 셀렉트를 통해서 데이터 제품으로써의 인프라를 만들어내는 개발이 필요하다
* 이러한 기술적인 문제를 해결하는 것 즉, 구현 능력을 빠르게 갖추는 것 그리고 오픈소스 인프라 들을 잘 운영하는 것이 가장 중요한 선결 과제다
  * 스트리밍 데이터를 유지할 수 있는 카프카 클러스터의 구축과 현재 환경에서 커버할 수 있는 리소스 (인적 물적 예산) 등을 확보하는 것
  * 기 구축된 혹은 운영 중인 카프카 및 얀 클러스터의 운영 및 모니터링 도구를 제대로 이해하고 활용할 수 있는 능력
    * 옵스지니와 같은 전사적으로 도입하는 혹은 활용 가능한 도구 들을 살펴보고 적극적으로 활용하는 방안
    * 실 내에 기 사용하고 있는 부서와 협업을 통해 숟가락을 얹는 방안
    * 가장 최소화한 기능을 통해 우리가 직접 운영하는 방안 (가장 마지막에 고민해야 함)
  * 국 내외 스트리밍 데이터 파이프라인을 분석하고 어떤 그림이 우리에게 가장 적절한 아키텍처인지 보는 눈을 가지는 것
    * 현재는 라인에서 채택하고 있는 그림과 아주 유사하며, 추가적인 자료들을 더 조사해서 비교해보아야 한다
    * 우리의 특징과 그들의 특징이 무엇이고 그에 따른 어떤 선택을 하는 것이 옳은 지 판단한는 것이 필요하다
  * 인프라 들을 활용하여 서비스 할 수 있는 도메인과 고객을 찾아서 요구 사항을 획득하는 것
    * 분석실과 같은 조직은 어느 정도 이제 관계가 깊어져가고 있으므로 더욱 확대해 나가는 것이 중요하고
    * 이외의 조직에게는 어떤 방식으로 홍보하고 우리의 서비스를 알릴 것인지에 대한 전략이 필요하다
  * 탑다운 방식과 바틈업 방식의 접근을 모두 취해야만 성공할 가능성이 높아진다
    * 엔터프라이즈 환경에서의 고객은 얻기도 어려울 뿐더라 제한된 이용자 특성을 가지며 몇 가지 특성을 가진다
    * 충분히 좋은 제품을 설계하고 개발할 때 까지 금전적인 지원이 계속되지 않을 가능성이 높다
    * 어느 정도 좋은 수준의 제품이 나오더라도 수동적이거나, 적극적인 사용을 안 할 가능성이 높다 (떠멱여주는 것에 익숙하다)
    * 큰 그림 위에서 인프라와 시스템을 설계하고 쌓아나가면서도 구체적인 고객의 요구사항을 통해 먼저 구현해주는 접근이 필요하다
    * 이러한 과정에서 엔지니어의 기술적인 만족도도 있을 수 있고, 충성고객을 획득할 수 있는 접근을 동시에 해야한다
* 탑 다운 방식을 위한 절차
  * 국내외 사례를 통한 일반적인 아키텍처 분석을 하되 해당 조직의 특성과 비교하여 아키텍처를 이해하는 것이 중요함
  * 우리 조직의 특성에 맞는 기본적인 아키텍처를 구성하되 현재 인적, 물적 리소스에 대한 제약과 한계를 고려해야 기술부채의 늪에 빠지지 않는다
  * 어느 정도 그림이 그려졌다면 이에 대한 <u>적극적인 공유와 기술적인 피드백 루프를 통해 강건하고 정보의 공유</u>를 통해 협동을 이끌어내야 한다
  *  조직의 <u>구성원 모두가 납득할 만한 그림과 목표가 일치해</u>야 한 팀으로써 바람직한 성장과 힘을 낼 수가 있기 때문이다
  * 각자 수행하는 솔루션이나 서비스가 본인의 목표 팀의 목표가 되다보면 같은 일을 한다는 생각이 들지 않을 수 있다
  * 탑 다운에서만 가능한 접근이며, 지속적인 기술 공유와 사례소개 및 토론문화 (기술적인 잡담습관)가 성공의 키
  * 결국 우리가 수행하는 모든 일과 서비스들이 하나의 그림에 블록을 채운다는 느낌으로 주간회의 때에 하는 것이 옳다
  * 우리가 올바른 방향으로 가고 있고, 결국에는 그 그림에 이를 것이라는 믿음을 줄 수 있는 리더가 되어야만 하겠다
* 바틈업 방식을 위한 절차
  * 아주 작은 성공(quick-win)을 반복적으로 이루는 것이 키 포인트이며, 이를 위해서는 핵심 이용자 즉, 1%의 충성고객이 필요하다
  * 사내 인원 1천명의 1%인 10명의 충성고객을 만들어야 하고 이미 존재한다면 그들을 위한 도구를 만들어줄 필요가 있다
  * 그들이 진정으로 원하는 것이 무엇인지 파악하고 지속적인 미팅과 대화, 잡담을 통해 진실을 알아내어야 하는 것이 목표다
  * 진실은 항상 저 너머에 있다(truth is over there) 개발자는 물론이고 고객도 자신을 모른다. 기술과 설계, 사용자 그 어딘가에 진실이 있다
  * 한 번에 알아낼 수 없고, 많은 실수와 도전이 필요한데 너무 큰 성공을 기대하고 노력한다면 그 또한 리스크가 커질 수 밖에 없다
  * 작은 성공과 빠른 피드백과 집중과 포기를 빠르게 선택할 수 있는 분위기가 되어야 하고, 이러한 태도를 권장하는 문화가 필요하다

## 모든 서비스는 하나로

* 커넥트, 셀렉트, 삭제 및 모니터링 서비스 까지 모두 하나의 큰 그림에 포함되어야 하고, 이를 통한 데이터 아키텍처를 그려나가는 것이 중요하다
  * 삭제 서비스의 경우에도 정적인 삭제 뿐만 아니라 스트리밍 데이터에 대한 삭제도 같이 고려해줄 수 있다면 좋겠다
  * 개별 마이크로 서비스들에 대한 접근성은 한 곳에서 처리할 수 있도록 구성하는 것이 바람직하다
  * 모니터링 서비스의 경우에는 옵스지니를 통한 통합을 할 수 있도록 그림을 그리면 좋을 것 같다
* 빅 파더
  * 어떤 시스템과도 독립적인 파이프라인을 구축할 수 있어야 하고, 간결하고 안정적인 서비스를 제공해야 한다
  * 간결하다는 의미는 복잡한 내부 구조를 몰라도 사용할 수 있어야 하고, 일차원적인 개발 스택을 가짐을 말한다
  * 커넥트를 통해서 제공하는 순간 불투명하고, 개발 스택만 복잡해지고 리스크가 커질 수 있다 발목 잡히지 말자
  * 모든 데이터 소싱 및 서비스의 근간이 되는 스트리밍 파이프라인이며, 델타와 아이스버그를 근간에 둘 수 있다
  * 카프카를 통한 데이터 입수와 안정적인 데이터 소싱을 위한 애플리케이션이 첫 번째 과제가 될 수 있다
    * 1안: kafka + spark-streaming + delta-lake
    * 2안: kafka + flink + iceberg
  * 그러면서도 유연한 멀티플렉싱과 대용량 데이터 처리를 위한 성능을 제공해야 하므로, 정확성, 안정성, 성능에 집중
    * 정확성:
      * 스트리밍 데이터의 특성상 **유실 및 중복에 대한 고려가 검토된 설계**가 필요하다
      * 애초에 **원본 카프카에 유실과 중복이 발생하는 경우에 대해서도 복구 전략과 대안**이 필요하다
      * 어느 정도 수준까지의 지연을 허용하고, 유실에 대한 복구 절차의 SLA 수준을 정해야 한다
    * 안정성:
      *  카프카 클러스터에 모든 데이터가 어느정도의 SLA 수준으로 제공받을 수 있는지가 중요
      * 일단 적재된 **카프카 메시지는 일차 클렌징, 검증 및 엔리치 등의 후처리 과정을 안정적**으로 수행
      * 이 과정을 스테이징이라 칭하고 안정적인 스테이징 전략이 중요하며 대용량 엔리치 안정화 필요
      * 이러한 스트리밍 데이터 소스에 대한 스키마 레지스트리 유지 및 표준화를 통한 서비스 검토 
      * 이러한 1차 데이터 소스를 직접 제공하는 것이 좋은지, 델타를 통한 스트림 소스가 적절한지 검토
      * 현재 구성된 플링크 적재기를 고려하지 않고 **스파크를 통한 델타 적재 서비스를 개발**해보는 것
    * 성능:
      * 충분히 **데이터가 커졌을 때에도 지연 없이 적재가 가능한 파이프라인 구성**을 해야함
      * 카프카 클러스터의 파티셔닝이 변경되는 것과 스테이징 변환 스케일링이 같이 증가해야 한다
      * 이러한 과정에서 **자체적인 장애나 유실, 중복이 없도록 하는 것**이 중요한 스트리밍 기술이 된다
* 커넥트
  * 1차 스테이징 작업은 기계적이고 빅파더를 신뢰하도록 구성하여야 하고, 이후 다양한 사용성에 집중하게 한다
  * 스키마 레지스트리를 활용하고, 스트리밍 데이터 소스의 사용성이 아주 편리하도록 구성하는 것에 집중
  * 원초적인 데이터 스키마를 입력하고 수정해서는 안되고, 안정적인 스키마 에볼루션과 관리가 되어야 한다
  * 스트리밍 데이터 카탈로그 관리의 핵심적인 역할과, 누구나 사용할 수 있는 셀프 스트리밍 서비스를 지향
  * 스키마:
    * 스트리밍 데이터의 모든 카탈로그를 관리하고 생산하는 역할을 담당할 수 있어야 한다
  * 호환성 & 안정성:
    * 핵심적인 데이터 소스와 싱크를 잘 선택하여 지원하며, 지원 갯수 보다 호환성과 안정성에 집중해야 한다
  * 사용성:
    * 누구나 스트리밍 데이터와 정적 데이터의 차이가 없도록 유연한 데이터 생성 및 지원을 하는 것
* 셀렉트
  * 인 게임의 다양한 이벤트를 인지하고, 누구나 게임에서 발생하는 다양한 사건을 트래킹 할 수 있습니다
  * 기존 커넥트를 아주 잘 활용할 수 있어야 하며, 무엇보다 로그 정의와 실제 사실에 대한 이해가 가장 중요합니다
  * 로그 정의서가 정의된 대로 잘 나오고 있는지, 그리고 어떤 로그가 어떻게 설계 되어 있는지에 대한 파악이 필요
  * 실제 게임 컨텐츠의 변화와 경험 그리고 실제로그의 저장에 대한 이해가 중요해서 게임의 이해도도 필요함
  * 게임 콘텐츠 이해 + 로그 정의서 이해 + 실제 발생하는 로그 + 지표의 의미와 추출 로직에 대한 이해와 통찰이 필요
  * 추가로 어떤 차트를 통해 시각화를 해야 이용자들이 잘 이해할 수 있고 전달될 지까지 고려하면 UI+UX 까지 필요
  * 정확성:
    * 다수의 지표를 제공하기 보다 하나의 지표를 제공해도 정확하게 제대로 된 지표를 그대로 표현하는 것
  * 사용성:
    * 어떠한 지표를 보기 위해 너무 많은 지식과 도구를 활용하기 보다 직관적인 도구를 통해 표현할 수 있을 것
    * 우리가 제공하고 싶은 지표의 가치를 가장 잘 표현하는 차트와 기능을 연구하고 빠르게 구현할 수 있는 능력
* 삭제
  * 정적 뿐만 아니라 스트리밍 데이터에 대해 모든 데이터 소스의 삭제와 리텐션 메타데이터를 관리할 수 있습니다
* 모니터링
  * 단순한 스파크 모니터링 뿐만 아니라 다양한 정적, 스트리밍 데이터 인프라에 대한 모니터링이 가능해야 합니다
  * 인프라 뿐만 아니라 우리가 생성하는 소프트웨어에 대한 지표, 장애의 사전 인지 및 대응 절차까지 가이드합니다

## 그래서 지금 진행할 작업은

>  빅 파더 프로젝트가 데이터 스테이징의 가장 기본이며 가장 안정적으로 동작해야 한다. 결국 스트리밍 애플리케이션을 안정적으로 동작하게 할 수 있는 파이프라인을 구축하는 것이 가장 핵심이다. 카프카로부터 데이터를 안정적으로 가져오는 관점에서 스파크 스트리밍은 원하는 크기만큼 필요한 데이터를 가져오는 구조이므로 밀리면 밀렸지 일반적인 장애는 프로그램 버그 외에는 없다. 결국 집계가 없는 스트리밍 애플리케이션은 파티셔닝과 카프카의 설정과 운영에 의존적인 인프라가 된다

### 스트리밍 소스 하둡 스테이징

>  델타 레이크 활용한 스파크 스트리밍 애플리케이션을 구현하고, 이를 하둡에 적재하는 애플리케이션을 구축하고 기본적인 성능 테스트를 수행합니다. 기본 데이터 적재는 카프카 클러스터에 콘솔 도구를 통해 밀어넣어둔 상태에서 가져가는 방식으로 테스트 하며, 최소한의 파티션, 레코드 수를 기준으로 테스트하고, 단계별로 성능을 테스트 합니다. 관련 프로젝트나 자료를 찾아보고 참고할 만한 설정이나 구현 방식에 대해 검토합니다. 이와 동시에 델타 레이크 자체에 대한 논문, 기술자료 및 제공된 실습을 모두 수행합니다. [delta-for-me](https://github.com/psyoblade/delta-for-me) 프로젝트를 통해서 학습을 수행합니다.
>
>  빠른 실습을 위해 파이스파크를 통해 대부분의 예제를 수행하고, 라이브 환경에서는 스칼라로 전환하고, 라이브 환경에서 대용량 데이터 성능 테스트 및 안정성을 확보합니다. 이때 카프카 설정 및 각종 모니터링 유틸리티에 대한 부분도 같이 배포되어 운영할 필요가 있습니다.

### 카프카 설정 및 운영

>  카프카 클러스터의 대용량 데이터 처리를 위한 확장, 운영 및 설정에 대한 자료 및 영상을 리뷰하고, 검토해야 할 사항들을 정리하고, 단계별로 적용하면서 성능을 테스트합니다. 특히 현재 상태를 인지하고 모니터링 할 수 있는 도구 들을 협업을 통해 구축 및 모니터링 할 수 있는 환경을 구축해야 한다

