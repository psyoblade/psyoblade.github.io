---
layout: post
title:  "델타 레이크: 고성능 ACID 테이블 저장소"
date:   2020-11-11 08:00:00 +0900
categories: psyoblade created
---

## 델타 레이크: 고성능 ACID 테이블 저장소

> [Delta Lake: High-Performance ACID Table Storage over Cloud Object Store](https://www.databricks.com/research/delta-lake-high-performance-acid-table-storage-overcloud-object-stores) 논문을 읽고 요약 합니다

### 요약

>  S3와 같은 클라우드 저장소의 경우 로컬 저장소와 다르게 키-값 저장소의 구현에 따라 ACID 트랜잭션이 지원하지 않거나, 디렉토리 목록을 읽는 등의 메타데이터를 읽는 데에 많은 비용이 든다는 점 그리고 일관성 모장에 제약이 있는 등의 어려움이 있습니다.
>
>  델타 레이크는 클라우드 객체 저장소 상에서 ACID 한 테이블 저장소 레이어를 제공하면서 효과적인 메타데이터 활용 뿐만 아니라 데이터 자동적인 파일 레이아웃 최적화, 업서트, 캐싱 그리고 감사 로그 등의 다양한 기능을 제공합니다.

### 1. 소개

>  현대의 분산 저장소(HDFS, S3, GFS 등)는 대용량 데이터의 저장과 읽기에 최적화 되어 있으며, 클라우드 기반의 객체 저장소의 경우는 키-값 저장소의 특성을 가진 블록 저장소와는 다른 구조와 특성을 가집니다. 그럼에도 불구하고 엔터프라이즈 환경의 데이터 처리와 관리를 위한 데이터 웨어하우스 및 BI 업무를 충분히 잘 수행할 수 있습니다. 다만, 가능하다는 것과 기존의 관계형 데이터베이스가 가지고 있던 ACID 한 트랜잭션 및 격리 수준을 제공하지 않음으로 인해 어려움은 존재합니다
>
>  첫째. 여러개의 객체 업데이트의 원자성을 보장하지 않을 뿐만 아니라, 다수의 질의 수행 간에 격리를 지원하지 않으며, 실행 도중에 실패한 데이터에 대한 롤백 처리 또한 애플리케이션 수준에서 고려가 필요합니다
>
>  둘째. 수백만 개의 객체를 가진 아주 큰 테이블의 경우에 메타데이터를 처리하는 비용이 아주 크기 때문에 다양한 상황을 고려한 설계 및 프로그래밍이 필요합니다. 수백만개의 파케이 파일의 메타데이터를 읽거나 하이브의 메타스토어 정보를 추출하는 것 등이 이에 해당하며, 클라우드의 객체 저장소의 경우는 더욱 더 일부 데이터를 스킵하거나 최적화 하기에 애로사항이 더 많습니다.
>
>  엔터프라이즈 환경의 대용량 웨어하우스 및 데이터 ETL 처리의 경우 대용량의 누적 데이터의 처리 및 변경이 일별로 빈번하게 발생하는 패턴을 가지고 있으며, 최근 GDPR 준수를 위한 개인정보 정보를 관리하기 위해 일부 레코드 혹은 일부 컬럼에 대한 일괄적인 변경 등의 대규모의 변경 등의 과제를 가지고 있습니다.
>
>  이러한 문제점을 해소하기 위해 파케이 포맷으로 인코딩된 write-ahead 로그 방식을 통해 ACID 속성을 지원하는 델타 테이블을 설계하여 클라이언트는 다수의 객체들을 한 번에 업데이트 할 수 있습니다.

* Time travel : 특정 시점 스냅샷 질의 혹은 롤백
* UPSERT, DELETE and MERGE operations : 객체의 효율적인 고쳐쓰기
* Efficient streaming I/O : 낮은 레이턴시로 작은 객체를 테이블에 저장하면서, 추후 성능을 고려하여 트랜잭션을 지원하는 큰 객체로 병합이 가능하며, 추가되는 객체에 대한 테일링을 지원하여 메시지 버스로 활용 가능
* Caching : 델타 테이블의 테이블과 객체는 불변이므로, 클러스터 노드는 안전하게 로컬 디스크를 통한 캐시가 가능
* Data layout optimization : 테이블 객체의 크기를 자동 최적화 지원하여 특정 디멘젼에 지역성(locality)을 확보할 수 있는 Z오더에 따른 저장이 가능
* Schema evolution : 테이블 스키마가 변경되더라도 다시 쓰지 않고도 오래된 파케이 파일들을 읽기
* Audit logging : 트랜잭션 로그 기반의 감사 로깅

![Figure 1: A data pipeline implemented using three storage systems or using Delta Lake for both stream and table storage.](https://user-images.githubusercontent.com/604173/205642859-a51862e9-8f93-432b-9559-2ae4e72795e6.png)

>  3가지의 서로 다른 저장 시스템(a message queue, object store and data warehouse)들을 통한 파이프라인 구성 대비 스트림 및 테이블 저장소 양쪽을 지원하는 델타 레이크를 비교합니다. 델타 레이크를 통해 데이터의 중복 관리를 하지 않아도 되며, 저비용의 객체 저장소를 운영할 수 있습니다.
>
>  이러한 기능을 통해 기존 데이터 웨어하우스 뿐만 아니라 데이터 레이크의 특징을 통합한 "레이크 하우스" 패러다임을 가능하게하며, 관리 뿐만 아니라 성능 문제도 해소할 수 있습니다.

### 2. 특징 및 도전과제

>  클라우드 기반의 객체 저장소의 API 의 성능 관점에서의 특징과, 효율적인 테이블 관리의 애로 사항을 설명하고 테이블 형태의 데이터 집합에 대해 어떻게 관리하는 지에 대한 설명을 합니다

#### 2-1. 객체 저장소 (Object Store)

* 객체 저장소의 개별 객체는 키에 의해 구분
* 파일 시스템 대비 디렉토리 혹은 객체의 이름 변경 비용이 크다
* S3 LIST 명령은 호출 당 최대 1,000개의 키 값들만 반환된다
* 수백만 객체의 데이터 집합의 LIST 호출은 수 분 이상 소요된다
* 객체 업데이트는 원자성을 가지지만 변경 시에는 객체 전체를 다시 써야만 한다
* 여러 디렉토리에 퍼져있는 객체들에 대한 원자성 지원은 일부 파일시스템만 지원한다

#### 2-2. 일관성 (Consistency)

* 클라우드 객체 저장소는 개별 키의 결과적 일관성(Eventual Consistency)을 제공하되 다수의 키는 보장하지 않는다
* 클라이언트가 새로운 객체를 업로드에 성공 하더라도, 또 다른 클라이언트는 그 즉시 해당 객체를 LIST 하지는 못할 수 있다
* 완전한 일관성 모델은 클라우드 제공자마다 다르게 구현되지만, S3 경우 PUT 직후 GET 이 가능합니다
  * 단, GET 실패 직후에 추가된 해당 객체의 Negative Caching 에 의한 예외적인 상황도 있습니다

#### 2-3. 성능에 영향을 주는 요소

* 객체 저장소의 높은 처리량을 얻기 위해서는 큰 순차적인 입출력과 병렬처리의 밸런스가 중요하다
* **읽기 동작**은 5~10ms 수준의 레이턴시로 동작하며 초 당 50~100mb 정도의 처리량을 보장한다
* 보다 높은 처리량을 보장받기 위해서는 병렬처리가 필수인데 VM 장비의 10G NIC 기준 dir 8~10개의 병렬처리가 적절하다
  * 10g bps = 10,240 bps = 10,485,760 bps = 1,310,720 bytes = 1,280 mbytes = 1.25gbytes 초 당 1G 전송
  * 초 당 100mb 전송이 가능하다는 가정 하에 최대 10개 정도 병렬로 전송을 하면 대역폭을 거의 다 쓰게 된다
* LIST 연산의 경우, 1kb 메타정보 조회 시에 10~100ms 정도 소요되므로, 많은 객체를 가진 경우 병렬처리가 아주 중요하다
  * 델타 레이크의 경우 분산 저장소에 메타데이터 파일로 저장되어 있으므로, 워커 노드에서 병렬로 수행하거나 혹은 드라이버 노드에서 멀티스레드로 수행합니다
* **쓰기 동작**은 전체 객체를 교체가 발생하며, 변경 사항이 전체 크기에 비해 작거나, 일부만 수정되어야 한다면, 객체는 가능한 작게 유지되는 것이 유리하다
* 결국 읽기가 자주 발생하는 테이블의 경우에는 I/O 및 메타데이터 조회를 줄이기 위해 파일의 수를 낮춰야 하지만, 변경이 자주 발생하는 테이블은 가능한 객체의 크기를 작게만들어 두어야 최소한의 변경만 이루어져 유리할 수 있다는 말이된다
* 객체 저장소의 테이블 저장소 사용 시의 시사점
  * 자주 액세스하는 데이터를 순차적으로 가까이 두고, 컬럼 기반 저장포맷을 사용합니다
  * 객체를 크게 만들되 너무 크지 않게 만들어, 삭제 및 수정의 비용을 줄입니다
  * LIST 작업을 피하고 가능한 사전순서 키 범위 요청을 통한 효과적인 동작을 수행합니다

#### 2-4. 테이블 저장소의 특징

> 객체 저장소의 특징에 기반하여 테이블 형태의 데이터 집합은 크게 세 가지 접근 방법을 취하게 됩니다.

##### 1. 디렉토리로 구분된 파일

>  오픈소스 기반 엔진 들이 취하는 디렉토리 기반의 파티션 구분과 파케이와 같은 컬럼 포맷으로 저장하며, 계층 기반의 파티셔닝 기법을 통해서 LIST 연산의 비용을 줄일 수 있습니다

* 다수 객체에 대한 원자성을 보장하지 않습니다
  * 트랜잭션 실패 시, 일부 성공한 수정사항이 다른 클라이언트에 노출될 위험이 있습니다
* 결과적인 일관성을 보장합니다
  * 트랜잭션이 성공한 경우라도 클라이언트는 객체의 일부만 조회될 수 있습니다
* 다소 성능이 떨어질 수 있습니다
  * 파티셔닝이 잘 구성되어 있다고 하더라도 갯수가 많다면 파케이 혹은 ORC 파일의 메타데이터를 읽는 비용은 충분히 클 수 있습니다
* 자동화된 관리기능이 부족합니다
  * 객체 저장소는 파일의 읽고 쓰기에 대한 API는 제공하지만, 데이터웨어하우스 관리에 필요한 버전 관리, 감사 로그 및 표준화된 테이블 관리 도구를 제공하지 않습니다

##### 2. 커스텀 스토리지 엔진

>  스노우 플레이크 데이터 웨어하우스 엔진 클라우드 기반의 저장소 엔진의 경우 별도의 관리 기능을 제공함으로써 일관성 문제들을 해소할 수 있으며, 이러한 엔진에서 클라우드 개체 저장소는 덤 블록 장치로 취급될 수 있으며 표준 기술을 사용하여 클라우드 개체에 대한 효율적인 메타데이터 저장, 검색, 업데이트 등을 구현할 수 있습니다. 다만 비용적인 문제가 가장 큰 허들이 됩니다.
>
>  아파치 하이브의 경우에도 Hive Metastore 와 ORC 와 같은 포맷을 통해서 ACID 한 트랜잭션 처리를 지원하며, 하둡 분산 저장소 위에서 데이터 웨어하우스를 구성할 수 있습니다.

* 모든 데이터 접근은 메타데이터 서비스를 이용해야 하므로, 저장소를 직접 읽는 것 대비 병목이 될 수 있습니다
* 파케이와 같은 공개된 포맷을 사용하는 것 대비 별도의 커넥터를 통한 개발은 추가적인 엔지니어링 비용이 발생합니다
* 독점적인 메타데이터 서비스를 사용하므로써 특정 벤더 혹은 서비스 제공자에 락인될 수 있습니다

##### 3. 객체 저장소의 별도 메타데이터

>  델타 레이크의 접근 방법은 클라우드 저장소에 직접 메타데이터 뿐만 아니라 트랜잭션 로그를 저장하게 됩니다. 데이터는 파케이 포맷이며, 기존의 다양한 프레임워크와 호환성을 보장합니다. 
>
>  Apache Hudi 와 Apache IceBerg 또한 유사한 접근을 통해 동일한 기능들을 제공하지만, 델타 레이크는 Z-order 클러스터링, 캐싱 뿐만 아니라 백그라운드 최적화 등의 다양한 특징을 제공합니다

### 3. 델타 레이크 저장포맷 및 접근 프로토콜

>  델타 레이크 테이블은 클라우드 객체 저장소의 디렉토리 및 다양한 트랜잭션 연산을 저장하는 파일 시스템으로 구성됩니다. 클라이언트는 긍정적인 동시성 제어 프로토콜을 통해 데이터 구조를 업데이트 합니다. 

#### 3-1. 저장포맷

<img width="477" alt="delta-lake-fig-2" src="https://user-images.githubusercontent.com/604173/206836484-86246fef-37d0-49ae-ac84-f5abe4f704a0.png">

##### 3-1-1. Data Objects

>  `mytable` 은 일자별로 파티셔닝 된 파케이 파일과, 모든 트랜잭션 로그를 저장하는 디렉토리로 구성되어 있으며, 파케이 파일은 컬럼 기반으로 다양한 압축 및 저장 포맷을 유지할 수 있습니다. 파케이 포맷을 사용할 수 있는 기존 프레임워크 들은 추가적인 도구 없이 사용이 가능합니다.
>
>  델타의 개별 데이터 객체는 생성된 유일한 GUID를 통해서 저장 관리되며, 이러한 객체들은 테이블의 개별 트랜잭션 수행에 따라 결정되는 파일들로 구성됩니다.

##### 3-1-2. Log

>  로그는 테이블 경로 아래의 `_delta_log` 라는 하위 디렉토리에 저장되며 제로 패딩 되는 증가하는 숫자 ID로 생성되는 JSON 파일로 이루어져 있습니다. 한 번의 구분된 트랜잭션에 의해 생성되는 원자적인 동작은 여러 *actions* 으로 구성되며 *checkpoints* 라고 말합니다. 여기에서 사용되는 *action* 에는 다음과 같은 종류가 있습니다.

* *Change Metadata*
  * 테이블의 첫 번째 버전은 반드시 **metaData** 액션이 필요하며 연속적인 **metaData** 액션은 이전의 정보를 덮어씁니다
  * 스키마, 파티션 정보, 저장 포맷 그리고 테이블에 대한 다양한 설정 옵션을 포함합니다
* *Add or Remove Files*
  * 데이터 추가 삭제 시에 발생하며, 클라이언트는 삭제 액션이 없었다면 모든 추가된 객체를 사용해도 됩니다
  * 데이터 객체의 레코드 추가 시에 전체 레코드 수, 컬럼 수준의 최대/최소/널 값 등의 데이터 통계도 같이 저장됩니다
  * 통계정보 또한 최신 버전이 이전 버전을 대체하게 됩니다
  * 삭제 액션은 레코드가 삭제된 타임스탬프 정보를 가지며, 그 즉시 삭제되지 않습니다
  * 이용자가 지정한 리텐션 시간 임계치가 지나고, 물리적인 삭제는 이루어집니다
  * 동시에 수행되는 다른 클라이언트의 읽기 작업도 이러한 지연된 삭제를 통해 문제없이 동작합니다
  * *dataChange flag*
    * **dataChange** 플래그는 추가 삭제 액션 시에 **false** 설정을 통해 이번 액션은 데이터를 재배치 및 통계정보에만 영향을 준다는 것을 의미합니다
    * 트랜잭션 로그를 테일링 하는 스트리밍 쿼리 수행 시에 이러한 플래그 값을 활용하여 테이블의 정렬 순서를 변경하는 등의 액션들은 스킵 할 수 있습니다.
* *Protocol Evolution*
  * 프로토콜 액션은 주어진 테이블을 읽고 쓰기 위해서 필요한 델타 프로토콜의 버전을 증가시킬때 사용됩니다
  * 클라이언트가 사용하는 기능의 호환성 보장 여부를 확인하기 위해서 사용합니다
* *Add Provenance Information*
  * 매 로그 레코드 객체는 어떤 사용자가 작업을 수행했는지를 포함하는 **commitInfo** 작업 등을 포함할 수 있습니다
* *Update Application Transaction IDs*
  * 

##### 3-1-3. Log Checkpoints

#### 3-2. 접근 프로토콜

##### 3-2-1. 읽기

##### 3-2-2. 쓰기

#### 3-3. 격리 레벨

#### 3-4. 트랜잭션 레이트

### 4. 주요 기능

#### 4-1. 시간여행과 롤백

#### 4-2. 효율적인 UPSERT, DELETE 그리고 MERGE

#### 4-3 스트리밍 입수 및 소비

#### 4-4. 데이터 레이아웃 및 최적화

#### 4-5. 캐싱

#### 4-6. 오딧

#### 4-7. 스키마

#### 4-8. 외부 연동

### 5. 사례

#### 5-1. 데이터 엔지니어링

#### 5-2. 데이터 웨어하우스

#### 5-3.

### 6. 성능

### 7. 결론



### 8. 질문과 답변

#### 1. 용어

##### Q1. S3 의 Negative Caching 이 뭔가요?

> <kbd>답변</kbd> : [네거티브 캐싱 (negative caching) / 음성 캐싱 / 음수 캐싱 / 부정 응답](http://www.codns.com/b/B05-216)은 마치 블랙리스트처럼 도메인레코드가 누락되었다는 사실을 "부정적인"캐시에 그 리스트(도메인 정보 테이블)들을 저장하고, 일정시간 동안 다시 찾지 않게 하여 **불필요한 네트워크 트래픽과 DNS 검색 지연을 줄이는 역할을 하는 DNS용 캐시**를 의미합니다 - [RFC 2308](https://www.rfc-editor.org/rfc/rfc2308)

##### Q2. Optimistic Concurrency Control Protocol 이 뭔가요?

> <kbd>답변</kbd> : **[낙관적 병행 수행 제어](https://ko.wikipedia.org/wiki/%EB%82%99%EA%B4%80%EC%A0%81_%EB%B3%91%ED%96%89_%EC%88%98%ED%96%89_%EC%A0%9C%EC%96%B4)**(Optimistic concurrency control, OCC), **낙관적 동시성 제어** 또는 **낙관적인 잠금**(optimistic locking)은 [관계형 데이터베이스 관리 시스템](https://ko.wikipedia.org/wiki/관계형_데이터베이스)과 [소프트웨어 트랜잭셔널 메모리](https://ko.wikipedia.org/wiki/소프트웨어_트랜잭셔널_메모리)와 같은 트랜잭션 시스템에 적용되는 [동시성 제어](https://ko.wikipedia.org/wiki/동시성_제어) 방식이다. OCC는 복수의 트랜잭션이 서로를 간섭하지 않고도 종종 완수될 수 있다고 가정한다. 실행 중에 트랜잭션은 이러한 자원들에 락(lock)을 획득하지 않은 채 데이터 자원을 사용한다. 커밋 전에 각 트랜잭션은 다른 트랜잭션이 읽힌 데이터를 수정하지 않음을 확인한다. 이 검사 도중 충돌되는 수정이 확인되면 커밋 중인 트랜잭션은 롤백되고 다시 시작이 가능하다.
>
>  즉, 분산 저장소를 기반으로 하는 하이브 혹은 델타 테이블을 읽고 쓸 때에 누구도 같이 사용하는 클라이언트가 없다는 가정 하에 데이터를 읽고 쓸 수 있다고 가정함으로써, 높은 처리량과 낮은 복잡도를 유지하는 장점을 가질 수 있습니다

