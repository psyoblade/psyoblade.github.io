---
layout: post
title:  "데이터 레이크 시대를 대비하라"
date:   2020-10-13 00:02:00 +0900
categories: psyoblade update
---

## 데이터 레이크 시대에 무엇을 대비해야 하는가?

> 거창한 제목 같은데 팀의 다음 해의 목표를 위해 여러가지 생각을 하고 있다. 데이터 레이크, 데이터 메시, 레이크 하우스 그리고 어떤 기술 어떤 인프라를 공부해야 하는지, 현재 나의 위치에서 할 수 있는 일과 해야하는 일 그리고 동료와 같이 이루어 내어야 하는 일 등등

### 데이터 엔지니어링의 역사

* [데이터 아키텍처 중심으로 풀어가는 **데이터** **엔지니어링** 역사](docs/데이터_엔지니어링_역사_v1.1.pdf)

### 일단 나열해 보기

* 데이터 레이크 구축 및 운영의 방향성은 결국 시티즌 데이터 사이언티스트 들의 세상이 될 것이다. 즉, 어느 정도의 기술만 익힌다면 누구나 기술의 민주화에 힘입어 손쉽게 도구와 애플리케이션을 만들어 낼 수 있어야 한다. 
* 그러한 세상이 우리가 지향하는 아니 조만간 도래할 아니 이미 도래한 현실이라 생각한다. 우리 주변에는 그러지 않게 느껴질 지 몰라도 실제로 그렇지 않다. 이미 그러한 세상은 와 있고, 바로 내 주변에 그런 사람이 많이 없었을 뿐이라 생각한다.
* 데이터 웨어하우스에서 데이터 레이크로 그리고 레이크 하우스를 거쳐 데이터 메시 아키텍처를 지향하며 데이터 환경은 진화해 나가고 있다. 결국 우리가 운영하는 생활하는 데이터 환경은 결국에는 클라우드의 축소판 혹은 클라우드에서 제공하는 문화를 따라가는 것이 바람직한 방향이라고 본다
* 데이터 사용자는 보다 엔지니어링 혹은 기술적인 학습을 통하여 직접 데이터 제품을 만들어내고 데이터 오너로써 역할을 강화해야 할 것이며
* 플랫폼 개발자는 지금 보다 더욱 인프라 혹은 자동화된 플랫폼의 개발에 박차를 가해야 할 것이다. 이 말인 즉슨 클라우드 서비스와 유사한 셀프 서비스를 제공 받을 수 있는 플랫폼을 구축 혹은 서비스 해야 한다는 말이 된다

### 데이터 메시 아키텍처의 원칙

* 도메인 지향 분산형 데이터 소유권
* 플랫폼으로서의 셀프 서비스 데이터 인프라
* 제품으로서의 데이터
* 통합 컴퓨팅 거버넌스

>  관련 전자 책을 더 리뷰하고 꾸준히 읽어 나가야 하고 이를 설파하고 실천해 나가야 한다

### 지금 당장 해야 할 일

* "통합 컴퓨팅 거버넌스" 관점의 기반 인프라에 대한 기술 내재화를 준비하는 것이 중요하지 않을까?
* 결국 끝까지 살아남을 기술과 인프라 서비스의 근간을 갖추는 것과 그러한 인력을 만들어 내는 것에 집중해야 한다
  * 결국 스트리밍 데이터 파이프라인을 통해 저장을 하게 되는 것이 가장 바닥에 깔려 있는 인프라
* 좀 더 확장해 보자면 몇 가지 데이터 소스로 구분해볼 수 있겠다
  * 시스템 혹은 서비스 데이터
  * 모바일 장치 데이터
  * 사물인터넷 데이터
  * 엣지 컴퓨팅을 통한 데이터
* 데부분의 데이터는 스트림 형태일 가능성이 높고 다양한 스키마와 복잡한 데이터 포맷을 가지게 될 것이다
  * 스트리밍 데이터를 받아들 일 인프라 기술에 대한 내재화 및 인프라 경험
  * 다양한 스키마와 유연한 스키마 모델링이 가능한 소프트웨어 도입, 운영 및 표준화
  * 스트리밍 파이프라인과 기존의 분석을 위한 영구 저장소에 저장하는 기술 및 인프라

### 어떤 기술과 어떤 노력이 필요한가?

* 대용량 스트리밍 클러스터 구축 및 운영 - apache kafka
* 스트리밍 데이터를 안정적으로 영구 저장소에 저장 서비스 - delta lake, iceberg, hudi
* 스트리밍 데이터 레지스트리 사용 및 표준화 - schema registry
* 저장된 데이터를 빠르고 안정적으로 조회할 수 있는 서비스 - ksql, hive, impala, spark
* 마이크로 서비스 기반의 데이터 애플리케이션을 빠르게 개발할 수 있는 기술 - spring boot, thymeleaf, react, spring batch
* 안정적인 데이터 레이어 기술 - mysql, spring jpa

### 어떤 전략으로 진행해 나가야 하나?

* 기술 내재화 및 안정화가 되기 까지 내부 프로젝트로 진행하되, 가볍고 적용하기 용이한 모바일 스트림의 오너십을 가져온다
* 모바일 스트림 오너십을 통해 카프카 클러스터의 기술 내재화, 운영 및 확장에 따른 기술을 습득한다
* 모바일 스트림 데이터를 카파 아키텍처 구성으로 원천 소스로 제공한다 (truth of source)
  * 여기서 원본 로그를 그대로 전달할 수도 있지만, 1차 가공한 데이터를 제공한다 (cleansing, valid, enrich, schema)
  * 조직 내에서 믿을 수 있는 데이터를 믿을 수 있는 상태로 상시 스트림 데이터로 제공하는 역할
* 1차 스트림 파이프라인 및 데이터 소스를 제공할 수 있게 되었다면 2차로는 영구 저장소에 저장
  * 스트림 파이프라인을 활용하여 영구 저장소인 하둡 과같은 분산 저장소에 저장한다
  * 이 때에 델타 혹은 아이스버그 같은 스트림/배치 파일포맷을 통해 저장하는 기술을 습득한다
  * 기존의 실시간, 10분, 1시간 지표등은 델타를 통한 스트림 애플리케이션으로 대체될 수 있다
  * 이렇게 생성된 데이터는 일 배치 작업에서 재활용되며 스트림과 배치는 더 이상 구분되지 않는다
  * 이러한 아키텍처를 델타 아키텍처라 부른다
* 람다, 카파 그리고 델타 아키텍처로 하나로 정해지는 것이 아니라 공존한다
  * 빅브라더는 전형적인 람다
  * 커넥트는 카파를 지원하는 강력한 인프라
  * 델타 레이크를 통한 스트림 및 배치 적재를 통한 기존의 빅마마를 델타 아키텍처로 전환 합니다
* 여태까지의 방향성과 더불어 기존의 셀렉트, 커넥트를 성숙하게 하고 발전 시키는 대에만 집중을 합니다.
  * 즉, 새로운 프로젝트는 외부적으로는 없으며, 내부적으로는 위와 같은 기술 내재화를 합니다
  * 외부적으로 빅마마 개선은 커넥트와 연동하여 실시간 지표 전환에 촛점을 둡니다.
  * 배치 작업은 기존과 동일하게 가져가는 것으로 보고 하고 델타 아키텍처의 근간을 마련합니다

### 개인적인 목표를 말하라고 하면?

* 현재 진행 중인 커넥트와 셀렉트의 데이터 센터 내의 서비스 활성화가 첫 번째 목표입니다
  * 커넥트는 스트림 데이터 소스 제공자로써의 역할입니다.
  * 스트림 데이터 소스의 근간을 이루는 도메인 수준의 데이터 제공자로써 수집기술팀에서 반드시 관리해야 합니다.
  * 해당 데이터에 대한 스키마, 검증, 품질 및 확장 까지의 하나의 제품으로써의 데이터 소스를 제공해야 합니다
  * 이러한 데이터 제품을 활용하여 많은 애플리케이션을 구축하는 것은 이제 시티즌 데이터 과학자 혹은 데이터 분석가가 됩니다. 혹은 타 조직 혹은 타 팀의 데이터 엔지니어가 될 수도 있습니다.
  * 이 과정에서 필요로 하는 다양한 셀프서비스 데이터 인프라는 데이터 센터가 제공해야 합니다. 현재와 유사합니다.
  * 여기서 빅브라더(커넥트)가 큰 역할을 해주어야 합니다. 배치 처리는 기존의 서비스들이 담당을 하게 되고, 스트리밍 처리는 커넥트가 담당하게 됩니다. 셀렉트는 이러한 인프라를 통해서 생성한 완전한 스트리밍 애플리케이션이 라고 말할 수 있습니다.
  * 대표적인 스트리밍 애플리케이션이 됩니다. 셀렉트는 플랫폼이나 애플리케이션 개발을 할 수 있는 플랫폼이 아닙니다. 순수하게 이용자가 인게임 데이터를 아주 잘 활용할 수 있도록 제공하는 조금 일반화 된 서비스라고 생각합니다
* 델타 레이크 기술을 통한 카프카 스트림을 하둡 클러스터에 적재하는 프로젝트를 진행 중이며, 연말 까지 POC 결과를 제공합니다
  * 업무 협의를 통해서 모바일 카프카 데이터에 대한 협의는 진행 중이며, 활용하여 전환 및 성능 테스트를 진행할 예정입니다
  * 전체 모바일 데이터에 대한 처리를 위한 스트림 및 배치 처리를 위한 저장 및 조회 레이턴시 확보가 우선입니다
  * 단계적으로 실시간과 10분 1시간 지표들을 선별적으로 전환하는 것도 포함됩니다
  * 1차 POC 와 방향성이 결정되면 성능 향상이나 내년 업무 계획으로 개발은 시니어+주니어 개발자로 진행할 예정입니다
* 팀 내에 핵심적인 인프라 관리자 및 개발자의 역량을 강화하기 위한 계획을 세우고 있습니다
  * 스트림 파이프라인의 핵심인 카프카 관리자
  * 스프링 및 다양한 데이터의 저장소인 마리아디비 관리자
  * 서빙 레이어 수준에서 가장 중요한 클릭하우스 관리자
  * 레거시 서빙 레이어 핵심 엔진 몽고디비 관리자
  * 이미 잘 알고 있는 시니어 엔지니어가 아니라 앞으로 더 많이 배우고 운영해야 할 주니어 개발자 4명이 담당
  * 2개월 단위로 관련 과제를 줄 생각이고 기술 공유를 통해서 역할과 책임을 명확히 할 생각

