---
layout: post
title:  "10/07 (화) 온라인 강의 어떻게 시작하면 좋을까?"
date:   2025-10-07 09:55:00 +0900
categories: psyoblade created
---

## 루틴: 2025년 10월 7일 (화)

>     첫 번째 단계로 온라인 강의의 방향성과 어떤 컨셉으로 진행하는 것이 경쟁력있는 강의나 자료가 될 것인지를 고민하고, 강의 개요서를 작성하는 것이 목적이다. 즉 <u>단순 개념 강의는 경쟁이 너무 치열</u>하여 대체제가 많다. 특히 GPT 통한 기본 학습은 누구나 할 수 있고 나보다 더 기계가 잘하고 있기 때문이다. 또한 <u>중요한 점은 촬영 기술 혹은 기법</u>이 아니라 **콘텐츠 큐레이션력** 즉, `무엇을, 어떤 순서로, 어떤 맥락에서 보여줄지 결정하는 능력` 이며, 끝으로 **꾸준한 관리가 가장 중요하다** 즉, 먹는 장사와 마찬가지로 한 두달 하다 마는 것이 아니라 `5년 10년을 꾸준히 영상을 올리고 독자와의 Q&A 등을 통해서 꾸준하게 커뮤니케이션 하는 것 또한 보충자료 업데이트까지  지속`해야 살아남을 수 있는 컨텐츠가 될 수 있다.
>
>     영상을 만들 때에 항상 고민되는 것이지만 나에게 맞는 스타일을 찾는 것이 가장 먼저가 되어야 할 것 같다. 그래야 지속할 수 있고 자연스럽게 영상이 만들어질 것 같다. 

### 오늘의 작업 이력

#### 중요한 일

* 좋은 큐레이션이란 무엇인지 이해하고 말할 수 있다
* 스파크 스트리밍 실전 강의 10분 영상을 위한 큐레이션 하나를 만든다

#### 이력

* 10/7 (화) 10:00 ~ 11:00 워밍업 및 큐레이션 이해

* 10/7 (화) 11:00 ~ 12:00 큐레이션 바탕으로 시나리오 작성
* 10/7 (화) 22:00 ~ 23:00 실습 가능한 로컬 환경 구성
* 10/8 (수) 08:00 ~ 09:00 같은 삽질을 통해서 로컬 개발 환경 구성
* 10/8 (수) 09:00 ~ 10:30 foreach-batch 방식을 이용한 예제 구현

#### 남은 일

* mongo-connector 방식을 이용한 예제 구현

### 1. "좋은 큐레이션"이란?

#### 1-1. "큐레이션이 없는" 강의의 예

>     “Spark Streaming은 이렇게 설치하고, 이건 코드예요, 여기서 foreachBatch를 쓰면 데이터를 Mongo에 저장할 수 있습니다.”

* 정보는 많지만 **순서도, 맥락도, 이유도 불명확**
* 듣는 사람은 “**왜 이렇게 해야 하지?**”라는 질문이 생김
* 결과적으로 **‘지식 전달’은 되어도 ‘이해’는 안 됨**

#### 1-2. "큐레이션을 잘 전달하는" 강의의 예

> “Spark Streaming으로 데이터를 처리할 때 가장 어려운 점은 **중복과 유실을 어떻게 방지하느냐**입니다. 그래서 오늘은 **‘중복과 유실 없이 안전하게 데이터를 저장하는 설계’**를 주제로 살펴보겠습니다"
>  1️⃣ 먼저 **데이터 소스**인 Kafka에서 **offset이 어떻게 관리되는지**,
>  2️⃣ 다음으로 **Spark Streaming**이 `foreachBatch`를 통해 데이터를 어떻게 **안전하게 처리하는지**,
>  3️⃣ 이어서 **MongoDB**에서 **upsert 키 설계**를 통해 **중복을 제거하는 방법**,
>  4️⃣ 마지막으로 **checkpoint**를 통해 **유실을 방지하는 방법**을 차례대로 알아보겠습니다.

* 듣는 사람이 **‘이 강의가 어떤 맥락에서 진행되는지’**를 바로 이해
* 배울 내용의 **흐름, 중요도, 연결관계**가 선명함
* 강의가 “정보”가 아니라 “**이야기(스토리)**”로 느껴짐

#### 1-3. 지식을 설계하는 방법을 배우는 것

>  “콘텐츠 큐레이션력은 **지식을 나열하는 게 아니라, 지식을 설계하는 힘**이다.”

| 구분          | 설명                             | 예시                                                |
| ------------- | -------------------------------- | --------------------------------------------------- |
| **선별력**    | 전달할 핵심을 고르는 힘          | “Spark Streaming의 수십 개 기능 중 ‘멱등성’에 집중” |
| **맥락화**    | 기술적 내용을 이야기 구조로 연결 | “이 기능을 왜 써야 하는가 → 장애 사례로 시작”       |
| **시퀀싱**    | 학습자 수준에 맞게 순서를 설계   | “Kafka → Spark → Mongo 순으로 점진적 난이도 구성”   |
| **비주얼화**  | 시각적 흐름을 설계               | 복잡한 아키텍처를 한 장 그림으로 요약               |
| **전달 설계** | 감정·스토리·리듬을 조절          | “실패 사례로 시작해 해결로 마무리” 구조             |

### 2. "실무에서 살아남는: Spark Streaming 을 활용하여 MongoDB로 안전하게 적재하기"

#### 2-1. 실시간 지표 제공을 위한 지표 생성 및 조회용 데이터베이스

> “예를 들어, **신규 모바일 게임 ‘Project Orion’** 의 모바일 클라이언트로부터 SDK 등을 통해서 다양한 클라이언트 이벤트가 Kafka 클러스터로 제공된다고 가정해 볼게요. 유저 이벤트 로그가 실시간으로 Kafka로 쌓이고, 이를 여러 분석 시스템에서 바로 활용해야 합니다. 그런데 문제는, 같은 데이터가 중복되거나 일부가 유실되는 경우가 발생하면서  **‘실시간 과금 로그가 실제 매출과 맞지 않는다’**는 이슈가 생기죠.”

* 초 당 수백~천 메시지가 카프카 브로커에 저장되고 있는 상황
* 메시지는 JSON 포맷임을 가정하고 JDK 통한 스키마는 고정
* 브로커에 전송된 모든 메시지는 정상적인 메시지임을 가정
  * 단, 클라이언트 SDK 수준에서 Exactly-Once 보장이 어려우며 At-least-once 방식으로 중복 전송이 가능한 상황은 후처리하는 것으로 가정

#### 2-2. Kafka Offset과 MongoDB Upsert를 결합한 스파크 스트리밍 멱등성 설계

>  “이 문제를 해결하기 위해 우리는 데이터를 전달받는 각 단계에서 ‘신뢰성’을 확보해야 합니다.  즉, **Kafka → Spark → MongoDB**로 이어지는 파이프라인 전체에서 중복과 유실을 방지하는 장치가 필요하죠.”

* 1️⃣ **Kafka offset 관리** – “컨슈머가 데이터를 어디까지 읽었는가를 명확히 기록하는 방식으로 중복 소비 방지”
* 2️⃣ **Spark foreachBatch 구조** – “한 번 읽은 데이터를 배치 단위로 처리하며, 장애 시 재처리도 가능”
* 3️⃣ **MongoDB upsert 설계** – “특정 키(예: gameId, userId, eventTime)를 기준으로 중복 삽입 방지”
* 4️⃣ **Checkpoint** – “Spark의 상태를 안전하게 저장해 유실 없이 재시작 가능”

#### 2-3. 결론

>  Spark Streaming으로 안전하게 적재한다”**는 건  단순히 데이터를 흘려보내는 게 아니라,  **언제든 재시작해도 같은 결과를 내는 구조를 설계하는 것**입니다.
>
>  (1안) 데이터 처리에서 가장 중요한 속성 중 하나는 **멱등성(Idempotence)** 입니다.  이 속성을 이해하고 구현할 수 있는지가,  단순히 프로그램을 작성하는 **개발자**와  시스템 전체의 신뢰성을 설계하는 **데이터 엔지니어(DevOps형)** 를 구분짓습니다
>
>  (2안) 데이터 엔지니어링에서 멱등성은 **단순한 기능이 아니라 사고방식**입니다. 코드를 짜는 개발자에서 벗어나, **운영까지 견디는 시스템을 설계하는 데이터 엔지니어**로 성장하려면 **멱등성을 설계의 중심**에 두어야 합니다.

#### 2-4. 성능

>  “이 구조를 적용한 이후,  동일 로그 중복 삽입률이 0.001% 미만으로 떨어졌고,  장애 발생 시 복구 소요 시간도 기존 15분 → 3분으로 단축되었습니 다. 실제로 저희 내부 테스트에서도 확인된 결과입니다.”

### 3. 개선 방향

#### 3-1. `foreachBatch` vs. `mongo-connector` 방식 비교

>  **전제(멱등키=`_id` 또는 `(topic,partition,offset)` + 체크포인트 + 유니크 인덱스)가 충족**된다면 **DSv2 방식이든 `foreachBatch+드라이버` 방식이든 “결과적으로 중복 없이” 적재**됩니다.  유실 방지는 스파크 **체크포인트/재시작** 설계를 동일하게 쓰기 때문에 두 방식 모두 동일한 수준으로 달성 가능합니다.  (단, 스파크 스트리밍 특성상 “엔드투엔드 정확히 한 번”의 이론적 보장은 아니고, **출력 멱등성으로 실용적 동일성**을 달성하는 것입니다.)

| 관점                  | DSv2 커넥터( `format("mongodb")` )                           | `foreachBatch + Mongo Java Driver` (bulkWrite)               |
| --------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **코드 길이**         | **짧음**: 옵션 몇 개로 종료 (대략 10~20 LOC)                 | **김**: 커넥션/배치/에러처리/업서트 모델 작성(대략 60~120 LOC) |
| **구현 복잡도**       | **낮음**: `idFieldList + operationType + upsertDocument`로 멱등 구성 | **중간~높음**: `$set/$setOnInsert`, Replace/Update 모델, flush 사이즈, ordered 등 직접 제어 |
| **유지보수성**        | **높음**: 스파크/옵션 중심 설정형 코드 → 팀 온보딩 용이      | **중간**: 세밀 제어 장점 있지만 개발자 교체 시 학습비용 존재 |
| **운영/옵저버빌리티** | **보통**: 커넥터 레벨 메트릭/로그에 의존                     | **높음**: 응답코드/예외/재시도 로직 등 세밀 로깅 가능        |
| **업데이트 유연성**   | **보통**: `replace`/`update` 중심, 레코드별 연산 변화는 제한적 | **높음**: 레코드별 `$set/$inc/$setOnInsert` 조합 등 임의의 연산 가능 |
| **샤딩/힌트 제어**    | **제약적**: 힌트/라우팅 제어 제한적일 수 있음                | **자유도 높음**: `hint`, 샤드키, writeConcern 등 호출단에서 세밀 제어 |
| **스키마 변동 대응**  | **안정 스키마**에 유리(`replace` 권장)                       | **스키마 잦은 변화**에도 유리(필드 부분 갱신으로 방어적 업데이트) |
| **성능(처리량)**      | **좋음**: 내부 일괄처리 최적화. 튜닝 포인트는 제한적         | **매우 좋음(상한 높음)**: flushSize/ordered/병렬성/히든 옵션 등 세밀 튜닝으로 극대화 가능 |
| **지연(P99)**         | **낮음~보통**: 설정형 경로, 튜닝 여지 적음                   | **낮음으로 튜닝 가능**: 대량 벌크/비순차(ordered=false) 조합으로 레이턴시 제어 |
| **장애 복구 제어**    | **보통**: 커넥터 내부 재시도에 의존, 단순·안정               | **높음**: 예외 유형별 재시도/드롭/격리 등 사용자 정의 가능   |
| **팀 표준화**         | **쉬움**: “스파크 옵션 표준 템플릿”으로 통일                 | **중간**: 공통 유틸/랩핑 필요(추상화 잘 하면 OK)             |

#### 3-2. 언제 어떤 솔루션을 추천하는가?

##### 3-2-1. **DSv2 권장 (기본값)**

- 목표: **구현·운영 단순성** + **결과 멱등성 보장**
- 데이터 모델: 비교적 **안정적 스키마**, 문서 **치환(replace)** 위주
- 요구: 특별한 샤딩/힌트/레코드별 연산이 **필수는 아님**
- 장점: **코드 짧음**, 빠른 도입, 팀 온보딩 용이

##### 3-2.2. **foreachBatch+드라이버 권장 (고급 제어/특수 요구)**

- 목표: **정교한 제어/최대 성능/특수 연산**
- 데이터 모델: **부분 업데이트**, `"$setOnInsert"`, `"$inc"`, 레코드별 **다양한 연산** 필요
- 요구: **샤딩 힌트**, `WriteConcern` 세분화, 예외별 **커스텀 재시도** 등
- 장점: **상한 성능**과 **운영 가시성**이 높음, 복잡하지만 미세 튜닝 가능

#### 3-3. 성능 개선을 위해서 어떤 부분을 고려해야 하는가?

- **유니크 인덱스**: 멱등키(`_id` 또는 `(topic,partition,offset)`)에 **유니크 인덱스/클러스터드(7.x)** 필수
- **배치 크기**: DSv2는 `maxBatchSize`, 드라이버는 `flushSize`로 **CPU/네트워크/스토리지** 균형점 찾기
- **ordered(false)**: 충돌(duplicate key) 발생 시 전체 배치 지연 방지, **P99 단축**에 유리
- **writeConcern**: 지연↔내구성 트레이드오프. 실무 기본은 `MAJORITY`, 초저지연은 낮출지 검토
- **체크포인트 위치**: 안정된 스토리지(HDFS/S3/분산FS). 토픽 재파티셔닝/리밸런싱 시에도 경로 고정

#### 3-4. 결론

> **현재처럼 멱등키 + 체크포인트가 갖춰진 환경**이라면 **두 방식 모두 “중복/유실 없이” 동일한 품질의 결과**를 냅니다. 빠르게 가고 팀 표준화**가 중요하면 **DSv2**. 세밀 제어/특수 연산/최대 성능 튜닝**이 필요하면 **foreachBatch+드라이버**를 택하세요.

### 4. 회고

#### 4-1. 카프카 도커 환경에서 컨테이너간 접근 실패

* 너무 긴 시간 (약 4시간) 삽질 끝에 성공하긴 했으나 성공만 했고, 배운 것은 없음
  * 기존 데이터 엔지니어링 카프카 대신 아파치 카프카 버전을 써야 한다는 점 - 언어팩 설치가 안 되어 콘솔 한글 출력 안 됨
  * KRaft 버전으로 옮겨가면서 해결되었다는 점 - 
  * 
