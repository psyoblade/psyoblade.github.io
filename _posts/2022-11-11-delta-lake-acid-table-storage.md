---
layout: post
title:  "델타 레이크: 고성능 ACID 테이블 저장소"
date:   2020-11-11 08:00:00 +0900
categories: psyoblade created
---

## 델타 레이크: 고성능 ACID 테이블 저장소

> [Delta Lake: High-Performance ACID Table Storage over Cloud Object Store](https://www.databricks.com/research/delta-lake-high-performance-acid-table-storage-overcloud-object-stores) 논문을 읽고 요약 합니다

### 요약

>  S3와 같은 클라우드 저장소의 경우 로컬 저장소와 다르게 키-값 저장소의 구현에 따라 ACID 트랜잭션이 지원하지 않거나, 디렉토리 목록을 읽는 등의 메타데이터를 읽는 데에 많은 비용이 든다는 점 그리고 일관성 모장에 제약이 있는 등의 어려움이 있습니다.
>
>  델타 레이크는 클라우드 객체 저장소 상에서 ACID 한 테이블 저장소 레이어를 제공하면서 효과적인 메타데이터 활용 뿐만 아니라 데이터 자동적인 파일 레이아웃 최적화, 업서트, 캐싱 그리고 감사 로그 등의 다양한 기능을 제공합니다.

### 1. 소개

>  현대의 분산 저장소(HDFS, S3, GFS 등)는 대용량 데이터의 저장과 읽기에 최적화 되어 있으며, 클라우드 기반의 객체 저장소의 경우는 키-값 저장소의 특성을 가진 블록 저장소와는 다른 구조와 특성을 가집니다. 그럼에도 불구하고 엔터프라이즈 환경의 데이터 처리와 관리를 위한 데이터 웨어하우스 및 BI 업무를 충분히 잘 수행할 수 있습니다. 다만, 가능하다는 것과 기존의 관계형 데이터베이스가 가지고 있던 ACID 한 트랜잭션 및 격리 수준을 제공하지 않음으로 인해 어려움은 존재합니다
>
>  첫째. 여러개의 객체 업데이트의 원자성을 보장하지 않을 뿐만 아니라, 다수의 질의 수행 간에 격리를 지원하지 않으며, 실행 도중에 실패한 데이터에 대한 롤백 처리 또한 애플리케이션 수준에서 고려가 필요합니다
>
>  둘째. 수백만 개의 객체를 가진 아주 큰 테이블의 경우에 메타데이터를 처리하는 비용이 아주 크기 때문에 다양한 상황을 고려한 설계 및 프로그래밍이 필요합니다. 수백만개의 파케이 파일의 메타데이터를 읽거나 하이브의 메타스토어 정보를 추출하는 것 등이 이에 해당하며, 클라우드의 객체 저장소의 경우는 더욱 더 일부 데이터를 스킵하거나 최적화 하기에 애로사항이 더 많습니다.
>
>  엔터프라이즈 환경의 대용량 웨어하우스 및 데이터 ETL 처리의 경우 대용량의 누적 데이터의 처리 및 변경이 일별로 빈번하게 발생하는 패턴을 가지고 있으며, 최근 GDPR 준수를 위한 개인정보 정보를 관리하기 위해 일부 레코드 혹은 일부 컬럼에 대한 일괄적인 변경 등의 대규모의 변경 등의 과제를 가지고 있습니다.
>
>  이러한 문제점을 해소하기 위해 파케이 포맷으로 인코딩된 write-ahead 로그 방식을 통해 ACID 속성을 지원하는 델타 테이블을 설계하여 클라이언트는 다수의 객체들을 한 번에 업데이트 할 수 있습니다.

* Time travel : 특정 시점 스냅샷 질의 혹은 롤백
* UPSERT, DELETE and MERGE operations : 객체의 효율적인 고쳐쓰기
* Efficient streaming I/O : 낮은 레이턴시로 작은 객체를 테이블에 저장하면서, 추후 성능을 고려하여 트랜잭션을 지원하는 큰 객체로 병합이 가능하며, 추가되는 객체에 대한 테일링을 지원하여 메시지 버스로 활용 가능
* Caching : 델타 테이블의 테이블과 객체는 불변이므로, 클러스터 노드는 안전하게 로컬 디스크를 통한 캐시가 가능
* Data layout optimization : 테이블 객체의 크기를 자동 최적화 지원하여 특정 디멘젼에 지역성(locality)을 확보할 수 있는 Z오더에 따른 저장이 가능
* Schema evolution : 테이블 스키마가 변경되더라도 다시 쓰지 않고도 오래된 파케이 파일들을 읽기
* Audit logging : 트랜잭션 로그 기반의 감사 로깅

![Figure 1: A data pipeline implemented using three storage systems or using Delta Lake for both stream and table storage.](https://user-images.githubusercontent.com/604173/205642859-a51862e9-8f93-432b-9559-2ae4e72795e6.png)

>  3가지의 서로 다른 저장 시스템(a message queue, object store and data warehouse)들을 통한 파이프라인 구성 대비 스트림 및 테이블 저장소 양쪽을 지원하는 델타 레이크를 비교합니다. 델타 레이크를 통해 데이터의 중복 관리를 하지 않아도 되며, 저비용의 객체 저장소를 운영할 수 있습니다.
>
>  이러한 기능을 통해 기존 데이터 웨어하우스 뿐만 아니라 데이터 레이크의 특징을 통합한 "레이크 하우스" 패러다임을 가능하게하며, 관리 뿐만 아니라 성능 문제도 해소할 수 있습니다.

### 2. 특징 및 도전과제

>  클라우드 기반의 객체 저장소의 API 의 성능 관점에서의 특징과, 효율적인 테이블 관리의 애로 사항을 설명하고 테이블 형태의 데이터 집합에 대해 어떻게 관리하는 지에 대한 설명을 합니다

#### 2-1. 객체 저장소

* 키-값 저장소는 개별 객체는 키에 의해 구분됩니다
* 

#### 2-2. 일관성

#### 2-3. 성능에 영향을 주는 요소

#### 2-4. 테이블 저장소의 특징

### 3. 저장포맷과 접근 프로토콜

#### 3-1. 저장포맷

##### 3-1-1. Data Objects

##### 3-1-2. Log

##### 3-1-3. Log Checkpoints

#### 3-2. 접근 프로토콜

##### 3-2-1. 읽기

##### 3-2-2. 쓰기

#### 3-3. 격리 레벨

#### 3-4. 트랜잭션 레이트

### 4. 주요 기능

#### 4-1. 시간여행과 롤백

#### 4-2. 효율적인 UPSERT, DELETE 그리고 MERGE

#### 4-3 스트리밍 입수 및 소비

#### 4-4. 데이터 레이아웃 및 최적화

#### 4-5. 캐싱

#### 4-6. 오딧

#### 4-7. 스키마

#### 4-8. 외부 연동

### 5. 사례

#### 5-1. 데이터 엔지니어링

#### 5-2. 데이터 웨어하우스

#### 5-3.

### 6. 성능

### 7. 결론